{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e0348a",
   "metadata": {},
   "source": [
    "## Model Exploration for Vegetable Classification\n",
    "### Introduction\n",
    "The goal of this project is to build an easy-to-use web application that allows users to identify vegetables from images using a trained machine learning model. It is designed primarily for educational purposes and as a demonstration of practical image classification using AI.\n",
    "\n",
    "Framing the Problem\n",
    "This notebook's goal is to train and fine tune a Image classification model to predict images of different vegetables, then evaluate our findings based on our models results.\n",
    "\n",
    "- This project uses a dataset from kaggle with hundreds of images of vegetables\n",
    "- After this intoduction, we will explore the data, such as the number of files split between the training, test and validation folders, image dimensions, etc\n",
    "- After Data Exploration, we will train, and fine tune multiple models to find which best fits our image data properly\n",
    "- We will evaluate the preformance of the all models. We'll look into accuracy, confusion metric, precision, recall, F1-score, precision-recall curve for the model.\n",
    "- We will explore examples in which our models failed to predict correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d4411",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Dataset (Source: [Vegetable Image Dataset](https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset/data)\n",
    ")\n",
    "The dataset contains 21000 images unique images of 15 different classes. I have modified the dataset and reduced the classes to 10 for training purposes.\n",
    "\n",
    "Image classes in dataset:\n",
    "\n",
    "- Bean\n",
    "- Broccoli\n",
    "- Cabbage\n",
    "- Capsicum\n",
    "- Carrot\n",
    "- Cauliflower\n",
    "- Cucumber\n",
    "- Potato\n",
    "- Pumpkin\n",
    "- Tomato\n",
    "We have reduced the dataset to 2000 images for training (200 in each class), 2000 for testing, and 1000 for validation (100 in each class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d807e0eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd98a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data/kaggle_vegetables_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# train_dataset = image_dataset_from_directory(\n",
    "#     \"data/kaggle_vegetables_small/train\",\n",
    "#     image_size=(180, 180),\n",
    "#     batch_size=32)\n",
    "# validation_dataset = image_dataset_from_directory(\n",
    "#     \"data/kaggle_vegetables_small/validation\",\n",
    "#     image_size=(180, 180),\n",
    "#     batch_size=32)\n",
    "# test_dataset = image_dataset_from_directory(\n",
    "#     \"data/kaggle_vegetables_small/test\",\n",
    "#     image_size=(180, 180),\n",
    "#     batch_size=32)\n",
    "\n",
    "def load_data(data_dir, img_size=(224, 224), batch_size=32):\n",
    "    train_dir = os.path.join(data_dir, \"train\")\n",
    "    val_dir = os.path.join(data_dir, \"validation\")\n",
    "    test_dir = os.path.join(data_dir, \"test\")\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",
    "    )\n",
    "    val_generator = val_test_datagen.flow_from_directory(\n",
    "        val_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",
    "    )\n",
    "    test_generator = val_test_datagen.flow_from_directory(\n",
    "        test_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical', shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edede8cd",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "We explored the use of multiple models to find the most efficient one for our task\n",
    "\n",
    "Models we investigated:\n",
    "\n",
    "CNN: Simple and great for basic image classification tasks.\n",
    "VGG16: Deep architecture and has high performance on image classification tasks.\n",
    "EfficientNet: High accuracy with less parameters and lower computational costs.\n",
    "ResNet50: Deep architecture and residual connections, can learn complex patterns.\n",
    "MobileNet: Lightweight architecture, and can quickly classify images with high accuracy.\n",
    "\n",
    "When these models are compiled, we're using the adam optimizer with a learning rate of 0.001 as it's one of the most efficient. We set the loss to categorical_crossentropy, which is suitable for our data multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(model_name, input_shape, num_classes):\n",
    "    if model_name == \"CNN\":\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    elif model_name == \"VGG16\":\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        model = Model(inputs=base_model.input, outputs=Dense(num_classes, activation='softmax')(x))\n",
    "    elif model_name == \"EfficientNet\":\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        model = Model(inputs=base_model.input, outputs=Dense(num_classes, activation='softmax')(x))\n",
    "    elif model_name == \"ResNet50\":\n",
    "        base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        model = Model(inputs=base_model.input, outputs=Dense(num_classes, activation='softmax')(x))\n",
    "    elif model_name == \"MobileNet\":\n",
    "        base_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        model = Model(inputs=base_model.input, outputs=Dense(num_classes, activation='softmax')(x))   \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model name\")\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33fa68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Training and Evaluation\n",
    "# ---------------------------------------\n",
    "\n",
    "def train_and_evaluate(model, train_generator, val_generator, test_generator):\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_lr=1e-6),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "    ]\n",
    "    history = model.fit(train_generator, epochs=20, validation_data=val_generator, callbacks=callbacks)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = np.argmax(model.predict(test_generator), axis=1)\n",
    "    y_true = test_generator.classes\n",
    "    \n",
    "    # Detailed metrics\n",
    "    report = classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys()))\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    return test_acc, report, conf_matrix, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Main Workflow\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "train_gen, val_gen, test_gen = load_data(data_dir)\n",
    "\n",
    "results = []\n",
    "models_to_test = [\"CNN\", \"VGG16\", \"EfficientNet\", \"ResNet50\", \"MobileNet\"]\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = len(train_gen.class_indices)\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\nTraining {model_name}...\\n\")\n",
    "    model = build_model(model_name, input_shape, num_classes)\n",
    "    test_acc, report, conf_matrix, history = train_and_evaluate(model, train_gen, val_gen, test_gen)\n",
    "    \n",
    "    # Save results\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": test_acc,\n",
    "        \"Report\": report,\n",
    "        \"Confusion Matrix\": conf_matrix\n",
    "    })\n",
    "    print(report)\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(f\"Model: {result['Model']}\\nAccuracy: {result['Accuracy']}\\n\")\n",
    "\n",
    "# Convert results to a DataFrame for better presentation\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Report\"])\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(results_df[[\"Model\", \"Accuracy\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3fbaee",
   "metadata": {},
   "source": [
    " precision    recall  f1-score   support\n",
    "\n",
    "        Bean       0.70      0.83      0.76       200\n",
    "    Broccoli       0.75      0.96      0.84       200\n",
    "     Cabbage       0.78      0.77      0.77       200\n",
    "    Capsicum       0.98      0.93      0.95       200\n",
    "      Carrot       0.98      0.99      0.98       200\n",
    " Cauliflower       0.93      0.71      0.81       200\n",
    "    Cucumber       0.91      0.77      0.83       200\n",
    "      Potato       0.89      0.98      0.94       200\n",
    "     Pumpkin       0.77      0.83      0.80       200\n",
    "      Tomato       0.91      0.71      0.80       200\n",
    "\n",
    "    accuracy                           0.85      2000\n",
    "   macro avg       0.86      0.85      0.85      2000\n",
    "weighted avg       0.86      0.85      0.85      2000\n",
    "\n",
    "\n",
    "Training VGG16...\n",
    "Model Performance Summary:\n",
    "          Model  Accuracy\n",
    "0           CNN    0.8480\n",
    "1         VGG16    0.9850\n",
    "2  EfficientNet    0.1000\n",
    "3      ResNet50    0.2865\n",
    "4     MobileNet    0.9985\n",
    "Model: CNN\n",
    "\n",
    "Test Accuracy: 0.8479, Precision: 0.86, Recall: 0.85, f1-Score: 0.85\n",
    "\n",
    "Model: VGG16\n",
    "\n",
    "Test Accuracy: 0.9850, Precision: 0.99, Recall: 0.98, f1-Score: 0.99\n",
    "\n",
    "Model: EfficientNet\n",
    "\n",
    "Test Accuracy: 0.1000, Precision: 0.01, Recall: 0.10, f1-Score: 0.02\n",
    "\n",
    "Model: ResNet50\n",
    "\n",
    "Test Accuracy: 0.2865, Precision: 0.31, Recall: 0.29, f1-Score: 0.26\n",
    "\n",
    "Model: MobileNet\n",
    "\n",
    "Test Accuracy: 0.9984, Precision: 1.00, Recall: 1.00, f1-Score: 1.00\n",
    "\n",
    "Comments\n",
    "The results from the reports show that the VGG16 and MobileNet models performed exceptionally well in classifying the vegetable images, with very high accuracy, precision, recall, and f1-scores. CNN also showed decent performance but not as close to VGG16 and MobileNet. EfficientNet and ResNet50 struggled, with EfficientNet performing very poorly, meaning there was an issue with our training of that model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Visualization - Accuracy and Loss\n",
    "# ---------------------------------------\n",
    "\n",
    "def plot_training(history, model_name):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(f'{model_name} Accuracy Over Epochs')\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'{model_name} Loss Over Epochs')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb48a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training for each model\n",
    "for model_name in models_to_test:\n",
    "    print(f\"Plotting training curves for {model_name}...\")\n",
    "    model = build_model(model_name, input_shape, num_classes)\n",
    "    _, _, _, history = train_and_evaluate(model, train_gen, val_gen, test_gen)\n",
    "    plot_training(history, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ccdd3d",
   "metadata": {},
   "source": [
    "CNN Accuracy and Loss Plots - Test Accuracy 0.86\n",
    "Accuracy Plot\n",
    "\n",
    "Training steadily increases as the model learns from the data.\n",
    "\n",
    "Validation increases but starts to plateau around epoch 10, indicating the model is reaching its capacity for the given task.\n",
    "\n",
    "Loss Plot\n",
    "\n",
    "Training decreases, showing the model is fitting the training data better with each epoch.\n",
    "\n",
    "Validation decreases initially but then stabilizes, indicating that the model is no longer improving much on unseen data.\n",
    "\n",
    "\n",
    "VGG16 Accuracy and Loss Plots - Test Accuracy 0.98\n",
    "Accuracy Plot\n",
    "\n",
    "Training increases steadily and eventually reaches close to 1.0, indicating the model over epochs is learning the patterns in the image training data effectively.\n",
    "\n",
    "Validation follows the training data consistantly, but the accuracy is higher than the training accuracy.\n",
    "\n",
    "Loss Plot\n",
    "\n",
    "Training loss starts high and decreases steadily as the model learns the data, reaching a very low value near the end.\n",
    "\n",
    "Validation loss decreases rapidly in the first few epochs and then gradually reduces, stabilizing around a low value.\n",
    "\n",
    "EfficientNet Accuracy and Loss Plots - Test Accuracy 0.10\n",
    "Accuracy Plot\n",
    "\n",
    "Training accuracy fluctuates significantly and remains very low throughout (around 0.09–0.11), suggesting the model struggles to learn from the training data.\n",
    "\n",
    "Validation stays constant around 0.1, indicating the model fails to generalize to unseen data.\n",
    "\n",
    "Loss Plot\n",
    "\n",
    "Training loss starts high at 2.35 and decreases slightly but remains close to its initial value.\n",
    "\n",
    "Validation loss remains almost constant 2.31, showing no significant improvement.\n",
    "\n",
    "ResNet50 Accuracy and Loss Plots - Test Accuracy 0.29\n",
    "Accuracy Plot\n",
    "\n",
    "Training increases over epochs but remains low (between 0.20–0.25).\n",
    "\n",
    "Validation fluctuates more and is generally higher than the training accuracy.\n",
    "\n",
    "Loss Plot\n",
    "\n",
    "Training shows a consistent decrease, meaning the model is learning from the training data.\n",
    "\n",
    "Validation decreases but shows some fluctuations, which suggests potential instability in validation performance.\n",
    "MobileNet Accuracy and Loss Plots - Test Accuracy 1.00\n",
    "Accuracy Plot\n",
    "\n",
    "Both the training and validation accuracy quickly reach near 100% accuracy.\n",
    "Loss Plot\n",
    "\n",
    "Both the training and validation losses decrease rapidly and stabilize at low values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ba438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Visualization - Confusion Matrix\n",
    "# ---------------------------------------\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, class_labels, model_name):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize confusion matrix for each model\n",
    "for result in results:\n",
    "    plot_confusion_matrix(result[\"Confusion Matrix\"], list(test_gen.class_indices.keys()), result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb230f",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Based on our analysis of each of these models, we have found that the most sucessful one in terms of predicting images of 10 different vegetables is the MobileNet model.\n",
    "\n",
    "MobileNet Model Overview\n",
    "\n",
    "Nearly predicted at 100% test accuracy (0.9985), only with 3 incorrect predictions of 2000 total test images.\n",
    "Predicted incorrectly for 2 images labeled as pumpkins, and 1 labeled as a capsicum.\n",
    "Other accurate models:\n",
    "\n",
    "VGG16: had a range of about 3-4 misclassified images per image class out of 200, with a test accuracy of 0.9850\n",
    "CNN: Struggled in some areas but not an outright failure, this model struggled specifically with classifying images of tomato, or cauliflower (Test accuracy: 0.86)\n",
    "Models that failed:\n",
    "\n",
    "EfficientNet: Completely inaccurate for our predictions, this model would require more fine-tuning as it only classifies images as pumpkins\n",
    "ResNet50: Model was all over the place in terms of predictions, test accuracy of 29"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
